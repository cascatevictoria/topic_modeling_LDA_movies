---
title: "Лабораторная №2. Тематическое моделирование: LDA."
author: "Виктория Болотова"
date: "06 12 2021"
output: 
    html_document:
      theme: cosmo
      code_folding: show
      toc: true
      toc_float: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Характеристика данных

Для этой лабораторной работы я взяла данные по описаниям сюжетов фильмов из Kaggle  (https://www.kaggle.com/jrobischon/wikipedia-movie-plots). Датасет популярен на Kaggle и очень хорошо составлен, поэтому мы можем ему доверять. Я хотела сделать эту лабораторную работу на данных предыдущей работы, но на них получились неинтересные результаты и слов было маловато. 

**Что я буду делать?**

Я хотела бы сделать тематическое моделирование трех схожих между собой жанров: crime, mystery, thriller и сравнить какие темы более характерны для какого жанра. Моделирование будет основываться на описаниях сюжетов фильмов, взятые из Википедии.

**Зачем?**

На самом деле, цель такой аналитической задачи отчасти прикладная - мне нравятся фильмы, связанные с судопроизводством, работой адвоката, расследованиями преступлений (тематика детектива), но тем не менее в таких жанрах зачастую есть моменты, которые мне очень неприятны, портящие впечатление от фильма - слишком бандитская стилистика, военная тематика и т.д. Есть темы, которые мне просто неинтересны, как ограбления, кражи. Мне самой "вручную" отследить характерные темы для каждого жанра будет очень затруднительно. Основываться на опыте просмотра фильмов тоже не вариант, так как надо помнить и изначально запоминать все темы и главное -  их суметь обнаружить. Я уже в течении нескольких лет мучаюсь с выбором жанра, когда выбираю фильм на вечер, поэтому пора обратиться к тематическому моделированию. 

**Исследовательские вопросы:**

* Есть ли систематические различия по долям темам в сюжетах фильмов схожих между собой жанров: криминальный, триллер и мистика? 
* Если да, то какие темы характерны для какого жанра? 
* Какие из трех жанров больше похожи друг на друга и по каким темам? 

Конечный объем корпуса (после всех шагов нормализации и после того как Mallet съест какую-ту часть слов): **184 066**.

# Чистка и нормализация текста

```{r}
library(dplyr)
library(readr)
movie_plots <- read_csv("wiki_movie_plots_deduped.csv")
nrow(movie_plots) #изначальное количество фильмов в данных
```

**Отфильтровываем данные и выбираем нужные переменные**

```{r}
plots_3_genres <- movie_plots %>% filter(Genre %in% c("crime", "mystery", "thriller")) %>%
  filter(`Origin/Ethnicity` %in% c("American", "British")) %>%
  select(Title, Genre, Plot)
nrow(plots_3_genres)
```


**Избавляемся от цифр, квадратных скобок и переносов строк**

Сейчас описания содержат цифры, квадратные скобки (т.к. используются ссылки в Википедии), переносы строк, поэтому давайте удалим их, используя регулярное выражение.

Сохраняем отчищенные описания в новую колонку `Clean_plots`

```{r}
library(stringr)
plots_3_genres$Clean_plot <- str_replace_all(plots_3_genres$Plot, regex("\\[+[0-9]+\\]"), " ")
plots_3_genres$Clean_plot <- str_replace_all(plots_3_genres$Clean_plot, "[\r\n]", " ")
plots_3_genres$Clean_plot <- str_replace_all(plots_3_genres$Clean_plot, "[0-9]+", " ")
glimpse(plots_3_genres)
```


**Избавляемся от слишком коротких слов**

Частый подход к нормализации текста на английском языке - это удаление коротких слов, давайте опробуем это!

```{r}
plots_3_genres$Clean_plot <- gsub("\\b\\w{1,3}\\s"," ", plots_3_genres$Clean_plot)
glimpse(plots_3_genres)
```

Сравнивая строчку Plot с Clean_plot, мы видим, что мы избавились от многих слов, как от арктиклей, так и от некоторых существитительных (например, `boy`).


**Избавляемся от имен собственных**

В описаниях содержатся очень много имен собственных, что негативно скажется для тематического моделирования, давайте избавимся от них, поскольку имена персонажей неинтересны для нашей исследовательской задачи. 

```{r}
library(textclean)
plots_3_genres$Clean_plot <- replace_names(plots_3_genres$Clean_plot)
```

Сейчас колонка `Clean_plot` не содержит имен собственных - отлично! Можно заняться токенизацией.

**Токенизация**

```{r}
library(tidytext)
plots_words <- plots_3_genres %>% unnest_tokens(words, Clean_plot)
```


**Лемматизация**

Лемматизация безусловно необходима.

```{r}
library(textstem)
plots_words$lem <- lemmatize_words(plots_words$words)
glimpse(plots_words)
```

Лемматизация прошла успешно - глаголы приняли свою начальную форму, а существительные теперь в ед.числе. 

**Ограничение лексикона**

Для описаний сюжетов фильмов характерны очень специфические термины, которые не встречаются в других описаний. Поэтому давайте удалим те слова, которые встречаются меньше чем в трех сюжетов фильмов. Сначала создадим таблицу `stop_lem`, в которой будут находиться те самые слова.

```{r}
stop_lem <- plots_words %>%
    count(lem, Title) %>%
    group_by(lem) %>%
    filter(n() < 5)
nrow(stop_lem)
```

Решение ограничить лексион привело к потере 16584 слов.

Давайте теперь посмотрим от чего мы избавились - стоило ли это того?

```{r}
glimpse(stop_lem)
```

Просмотрев все слова, я убедилась, что мы избавились от слов (и даже цифр), от которых действительно нужно было избавиться. 

Проводим антиджоин таблицы `plots_words` с таблицей `stop_lem`:

```{r}
clean_df <- plots_words %>% anti_join(stop_lem)
nrow(clean_df)
```

Конечный объем корпуса:  243297 слов. Мы не избавились от стоп-слов, поскольку будем это делать чуть попозже.

```{r}
options(java.parameters = "-Xmx1g")
```

**Преобразуем слова обратно в текст.**

Я решила не объединять описания сюжетов друг с другом, так как фрагменты сюжетов достигают длины в 50 слов, что является достаточным размером фрагментов текстов для LDA, поэтому мы теперь просто сформировываем заново описания сюжетов из соответствующих слов. Также, мы создадим две необходимые колонки для mallet:

* text
* docid


```{r}
plots <- clean_df %>% group_by(Title) %>%
    summarize(text = paste(lem, collapse=" ")) %>%
    mutate(docid = paste(Title, sep="."))
nrow(plots)
```

1444 - итоговое количество фильмов для тематического моделирования.

Сейчас давайте заранее подготовим табличку метаданных, которую потом будем джойнить с таблицей doc.topics.

Я создаю колонку id для каждой из таблиц, так как left join по названиям фильмам давал не очень хороший результат.

```{r}
plots$id <- rownames(plots)
plots_3_genres$id <- rownames(plots_3_genres)
```

Теперь сделаем left join, чтобы кол-во строк таблицы с метаданными `plots_3_genres` соответствовало кол-ву строк в финальной таблице `plots`, полученной с помощью воссоздания текста из токенов. 

```{r}
meta_df <- merge(x=plots,y=plots_3_genres,by="id",all.x=TRUE)
nrow(meta_df)
meta_df <- meta_df %>% select(- Title.y, - docid, - text, - Clean_plot, - id) # уберем ненужные колонки
meta_df <- meta_df %>% rename(Title = Title.x)
```

# Подготовка к LDA моделированию

Давайте подготовим внешний файл со стандартными стоп-словами в английском языке:

```{r}
library(stopwords)
library(readr)
write_lines(stopwords("en"), "stopwords.txt")
```

Благодаря этой операции мы получили список стандартных стоп-слов, но мы его дополним такими словами как, however, take, become, make, tell, ask, begin, much, also и т.д. и создадим новый файл.

Заранее определить, что включать в список стоп-слов сложновато - надо посмотреть на результат обучения модели - на слова, формирующие темы.

Теперь мы должны преобразовать нашу текстовую табличку в формат, пригодный для дальнейшего моделирования:

```{r}
library(rJava)
library(mallet)
mallet.instances <- mallet.import(id.array=plots$docid,
                                  text.array=plots$text, 
                                  stoplist="my_stopwords.txt")
```

## Выбор количества тем

Построив модели с несколькими значениями количества тем, я пришла к выводу, что для нашего количества фильмов и слов оптимальным значением является 20 топиков. При таком значении слова формирует наиболее осмысленные и интересные темы. 

А вот сейчас мы создадим по сути пустой объект с нужными для нас параметрами:

```{r}
topic.model <- MalletLDA(num.topics=20) # заготовка - контейнер с мешками, кол-во топиков
topic.model$model$setRandomSeed(53L)
topic.model$loadDocuments(mallet.instances) # загружаем не изначальные тексты, а специально предобработанные - mallet instances
topic.model$setAlphaOptimization(20, 50) # оптимизация гиперпараметров
```

* **итоговое количество токенов: 184560**

Теперь мы собирем статистику о словаре и частоте использования токенов для последующего использования (построения интерактивной визуализации)

```{r}
vocabulary <- topic.model$getVocabulary() # corpus dictionary
word.freqs <- mallet.word.freqs(topic.model) # frequency table
## top frequent words (by doc frequency)
word.freqs %>% arrange(desc(doc.freq)) %>% head(10)
```

* Интересно, что слово `find` встречается чаще всего в жанрах триллера, мистическом жанре и в криминальном - даже чаще слов `kill` и `murder`. Я не включила слово `find` в список стоп-слов, поскольку мне кажется оно интересным и не случайным для выбранного нами жанров. 

# Тренируем модель


```{r}
topic.model$train(500) # число - это кол-во итераций 
```

# Анализ результатов LDA

## Doc-topics

Создадим **doc-topics** таблицу, в которой:

* Каждая строка - это документ, в нашей случае один сюжет фильма
* Колонки - это выбранное нами количество тем
* А значение - это доли соответствующих сюжетов фильмов, приходящиеся на соответствующие темы 

```{r}
doc.topics <- mallet.doc.topics(topic.model, smoothed=TRUE, normalized=TRUE)
```

Значения долей топиков довольно-таки сильно варьируются по всей таблице (~ от 0.0008 до 0.4)

Хорошая новость заключается в том, что каждое измерение (топики) могут быть интепретированы (так как мы можем посмотреть на слова, которые и составляют топики) и при этом мы знаем кое-что интересное про сюжеты фильмов - какого они жанра!

## Word-topics

Давайте посмотрим на распределение слов по темам:

**Word-topics** таблица, в которой:

* Каждая строка теперь является темой
* Каждая колонка - это слово
* А значения - это вероятности, что слово принадлежит соответствующей теме

```{r}
topic.words <- mallet.topic.words(topic.model, smoothed=TRUE, normalized=TRUE)
```

## 3 топ-слова для каждой темы

```{r}
topic.labels <- mallet.topic.labels(topic.model, topic.words)
topic.labels
```

Темы получаются очень даже хорошие! 

* Есть прям интересные темы: больница (hospital life doctor), полет на самолете (plane passenger flight), расследование убийства (murder police detective), ограбление (gang bank robbery), наземные средства передвижения (train car truck) и морские (ship boat island) и т.д.


## Иерархическая кластеризация тем 

**Сходство по совпадениям тем в сюжетах фильмов**

На этой визуализации иерархическая кластеризация формирует кластеры топиков, которые встречаются в одних и тех же сюжетах фильмов - из связанных тем получаются кластеры.

```{r}
plot(mallet.topic.hclust(doc.topics, topic.words, 0), labels=topic.labels)
```


**Сходство по набору слов в темах**

Кластеризация тем, содержащих схожие наборы слов: 

```{r}
plot(mallet.topic.hclust(doc.topics, topic.words, 1), labels=topic.labels)
```


**Сбалансированное сходство по словам и фильмам.**

```{r}
plot(mallet.topic.hclust(doc.topics, topic.words, 0.5), labels=topic.labels)
```

# Интерактивная визуализация 

```{r}
library(LDAvis)
library(servr)
```

Для создания интерактивной визуализации нам нужно посчитать длину описаний сюжетов всех фильмов:

```{r}
library(stringr)
doc.length <- str_count(plots$text, boundary("word"))
doc.length[doc.length==0] <- 0.000001 # чтобы не делить на ноль
```

Еще один подготовительный шажочек на пути к интерактивной модели:

```{r}
json <- createJSON(phi = topic.words, theta=doc.topics, doc.length=doc.length, vocab=vocabulary, term.frequency=word.freqs$term.freq)
```

**Интерактивная визуализация**

```{r eval=FALSE}
serVis(json, out.dir="lda50", open.browser=TRUE)
```

Интерактивная визуализация показывает нам сходство тем по набору слов - составляющих темы и документов, в которых темы встречаются. 

Барчарт показывает:

* Синий цвет - общая частотность соответсвующего слова
* Красный цвет - частотность соответствующего слова именно в выбранной теме

Если мы сделаем лямбду равной 0, мы получим в списке топ-слов слова, которые встречаются только в выбранной нами теме, а если лямбда будет равна 1, то мы наоборот получим не очень-то и характерные слова в списке топ-слов - просто распостраненные в целом для корпуса. Поэтому стоит установить лямбду равной 0.5, чтобы получить метрику FREX (FRequency and EXclusivity), которая находит баланс между этими двумя крайностями.

Этот скриншот показывает нам темы и их расположение относительно друг друга (= сходство) в PCA измерении. Тут мы видим слова по метрике FREX для 12 темы. Эта интерактивная визуализация пронумеровывает темы в соответствии с их размером (1 тема - самая крупная, а 20 - самая маленькая). Соответсвенно, 12 тема - тема среднего размера, на нее приходится 2.6% всех слов. Как мы видим по списку топ-30 самых релевантных слов, тема 12 явно отражает контекст больницы (существительные: доктор, пациент, медсестра, операция, таблетка), (глаголы: лечить, спасать, испытывать, страдать). Интересно, что в теме больницы в выбранных нами жанрах персонажи чаще всего страдают от амнезии (есть само слово амнезия, есть существительное память и глагол помнить), а также присутствуют такие слова как головной мозг, `mental` и психиатр. 

![](./интерактивная_виз_1.PNG)

# Интепретация всех тем

## 1 тема: "Шум"

Первая тема - это самая большая тема, на нее приходится целых 23% токенов. В этой теме находятся самые частотные слова и изменение значения лямбды никак не меняет список топ-слов. 

Стоит отметить, что есть слова в первой теме очень частотные, которые тоже надо было включить в списко стоп-слов (такие как see, send, give, meet, come, next) - они никак не отражают специфическую лексику или какой-то интересный контекст, такие слова просто функционально необходимы для нашей речи. Однако, есть более специфические слова для выбранных жанров фильмов (такие как reveal, night, apartment, visit), но все-таки шума больше.

![](./1.PNG)


## 2 тема: "Преступление в жилом помещении"

На вторую тему 16% токенов, что тоже далеко не мало, однако тут слова поинтереснее, чуть более специфические и даже можно смело выделить тему - преступление в жилом помещении. Посмотрим на список топ-слов по FREX:

**Топ по FREX**

![](./2_FREX.PNG)

Эта метрика выводит в список топ-слов такие важные для этой темы существительные как house, home, room, inside, а также глаголы: enter, open, break (взламывание двери, окна и т.д.) - которые обозначают необходимые действия для входа в помещение, легальные и нелегальные - таковы жанры. Кроме того, во вторую тему попали слова, отражающие борьбу (attack, shoot, cause, confront) и попытки спастись (run, hide, attempt, try, phone - позвать на помощь c помощью телефона). 

**Топ по эксклюзивным словам**

![](./2_EX.PNG)


Давайте посмотрим какие слова характерны только для второй темы:

* Помимо inside появилось слово outside. 
* Появились новые слова важные для темы `Помещения`: глаголы knock (постучать), lock (запирать) и существительные: window (возможный вход в дом), knife (нож) - оружие, характерное только для этой темы - это логично, поскольку раз речь идет о жилом доме, то единственное оружие, которое под рукой у каждого человека дома - это нож. Раз есть слово нож, то есть и глагол зарезать (stab). 

Топ по эксклюзивным словам позволил нам узнать больше инсайтов о второй теме.

## 3 тема: "Последствия супружеской измены"

На третью по величине тему приходится 8% всех слов в корпусе, что тоже далеко не мало.

**Топ по FREX**

![](./3_FREX.PNG)

* В этой теме отражается брак (wide, husband, marry, marriage), но про детей и семейный быт ни слова и позже мы понимаем почему. По некоторым словам (affair, lover, woman, fall + love = fall in love) мы понимаем, что тема отражает семейную измену и ее последствия: подозрение и раскрытие - suspision, discover, indentify, determine,  месть - blackmail, poison и даже смерть (commit + suicide, die).

**Топ по эксклюзивным словам**

![](./3_EX.PNG)

* Много релевантных слов, которые мы еще не видели!
* divorce, wed, romantic, fiance (невеста), guilt (вина) - релевантны, но их синонимы были получены в предыдущей метрике
* А благодаря словам widow (вдова), inherit (унаследовать), motive, rich, alibi, fortune, estate, мы понимаем, что тема отражает сюжеты, где убийство мотивируется желанием получить наследство. 
* Тема отражает разные события именно в семье и именно между полами: измены, отравления, чей мотив - получение наследства. 


## 4 тема: "Расследование убийства & экспертиза доказательств"

4 тема содержит 6.8% всех слов корпуса. 

**Топ по FREX**

![](./4_FREX.PNG)

* Убийство, убийца, расследование, детектив, жертва, серийный (убийство или убийца), арест - можно сделать вывод, что эта тема отражает убийства и их расследования
* А такие слова, как отслеживание (track), подсказка (clue), доказательства (evidence) раскрывают контекст детектива. 

**Топ по эксклюзивным словам**

![](./4_EX.PNG)

* Синонимы с ранее выявленными словами: perpetrator
* Сбор улик и доказательств: fingerprint, informant, profile (убийцы видимо)
* Разработка теорий: theory


## 5 тема: "Бандиты & незаконная деятельность"

На 5 тему приходится 6.2% всех слов.

**Топ по FREX**

![](./5_FREX.PNG)

По списку топ-слов мы можем сделать вывод, что эта тема про бандитов (есть само слово gangster):

* Контекст денег: money, debt, cash, sell, financial, business
* Насилие: beat, threaten, force, shoot, kill
* Помещение: nightclub, club
* Азартные игры & наркотики: gamble, cocaine
* Интересно, что слово полиция - частое слово в корпусе, но в этой теме присутствует именно слово cop, так как оно более характерное для такого бандитского контекста

**Топ по эксклюзивным словам**

* Появилось еще слова, подчеркивающее контект азартных игр & наркотиков: casino, heroin
* Еще слова к контексту денег: wallet, payment, profit
* Синоним к слову бандит: thug (головорез)
* Mafia, mobster (мафиози) эксклюзивные и важные слова для 5-ой темы

## 6 тема: "Семья и ее пополнение"

Эта тема включает в себя 4.7% всех токенов.

**Топ по FREX**

![](./6_FREX.PNG)

* Семейные роли: father, daughter, son (+ boy, baby), child, parent, mother, brother и само слово - family (+ pregnant)
* Повествовательный контекст о жизни: year, town, young, live, life
* Похищения детей: kidnap, lose, disappearance
* Насилие: abuse, violent


**Топ по эксклюзивным словам**

* Mother, pregnant, baby, infant, birth, birthday - эксклюзивные слова для этой темы
* Новые семейные роли: grandmonther 
* Подростковый возраст: teenager, teenage, teen
* Насилие: traumatize
* Также, по этой метрике появились слова: orphan (сирота) и adopt, то есть в этой теме содержится момент усыновления ребенка
* Контекст похищения детей не виден по этой метрике

## 7 тема: "Сексуальное насилие"

**Топ по FREX**

![](./7_FREX.PNG)

* Женские персонажи: sister, girl, woman
* Слова, указывающие на сексуальное насилие: rape, blood, sexual, clothe, kiss, seduce
* Фотографии: photo, photographer, photograph
* Интересно, что здесь есть слово священник: priest - надо смотреть на данные

**Топ по эксклюзивным словам**

* Неожиданное слово для этой темы: anniversary
* Слово священник очень характерное для этой темы и только для нее
* Wash, bath, bathtub - появление этих слов может быть связано с тем, что по метрике FREX мы получили слово - кровь

## 8 тема: "Выживание в горах"

**Топ по FREX**

![](./8_FREX.PNG)

* climb, rope, mountain, helicopter, cliff - восхождение в горы, скалолазание
* rifle (винтовка), солдат
* rebel - повстанец
* camp, village

**Топ по эксклюзивным словам**

* cave (пещера)
* важное эксклюзивное слово - survivor
* hike
* Вьетнам


## 9 тема: "Противостояние государств"

**Топ по FREX**

![](./9_FREX.PNG)

* Самое релевантное слово для 9-ой темы: агент
* goverment, president
* Отражение разных государств: british, american, russian, soviet + union
* Вражда, терроризм, армия, война, вооруженные силы, nuclear (ядерное оружие)
* Миссия, секретная

**Топ по эксклюзивным словам**

* Второе по релевантности слово после государства - assassin (наемный киллер)
* Эксклюзивное для этой темы единственное государство - Россия: russian, soviet + union, moscow, russia 
* Другие гос.органы: embassy (посольство), federal + organization и т.д.
* Troop - войска


## 10 тема: "Банда беглецов"

**Топ по FREX**

![](./10_FREX.PNG)

* В этой теме события уже происходят, когда преступник или целая банда (gang) пойманы и находятся в тюрьме (prison, inmate, jail, prisoner) за соответствующее правонарушение (kidnap, robbery) или практически пойманы (raid, ambush - засада)
* Кроме того, тема 10 раскрывает и события беглого преступника (или банды), сбежавшего из тюрьмы (fugitive, escape, disguise - маскироваться) и его успех в этом (succeed, plan, arrange)

**Топ по эксклюзивным словам**

* Слово банда (gang) самое частотные из всего топ-списка, все-таки эта тема отражает именно группу преступников. Кроме того, эксклюзивным для этой темы является слово confederate - найти союзника, объединяться 
* Raid, inmate - эксклюзивны для 10-ой темы

## 11 тема: "Минирование предприятия и взятие заложников"

**Топ по FREX**

![](./11_FREX.PNG)

* Самое релевантное слово - бомба (а также есть слово bomber), а бомба использовалась, как мы начинаем понимать для причинения урона какой-то компании, заводу
* Интересные для этой темы и связанные логически между собой слова: record, video, computer, system, control, access - видимо бомбардировщики хотели удалить видео с системы видеонаблюдения или взламать/отключить ее - а для этого им нужен был доступ. Да и для расследования записи с камер важны, конечно. 
* Отражается захват заложников в этой теме (hostage)
* Есть такие слова, как employee, janitor (дворник) - наверянка они и стали заложниками и пытались позвать на помощь (caller)
* Вмешательство спецназа: swat, sniper (снайпер)

**Топ по эксклюзивным словам**

* detonate - взорвать 
* Еще подтверждения, что в этой теме минирование происходит именно компаний, предприятий (не магазинов) - corporate
* hack, software, dub - также подтверждения контекста взлома 
* deadline - преступники, минируя здание, часто ставят крайний срок - до которого их условия должны быть выполнены 

## 12 тема: "Лечение в больнице & потеря памяти"

По FREX мы уже разобрали эту тему до этого, поэтому давайте перейдем к следующей метрике:

**Топ по эксклюзивным словам**

* memory - самое частотное и эксклюзивное слово для этой темы
* другие проблемы со здоровьем & психикой: галлюцинации, рак, кома 

## 13 тема: "Шум"

**Топ по FREX**

![](./13_FREX.PNG)

* Эта тема - это набор слов, необходимый для описания сюжета любого **фильма** - тут нет специфической лексики для выбранных нами жанров. Эти слова используются с описаниях сюжетов фильмов для того, чтобы рассказать какие известные актеры играют какую роль (star), в целом про актерский состав (сast), где снимался фильм (studio), для описания важнейших сцен (stage), кто режиссер фильма (producer) и т.д. 


**Топ по эксклюзивным словам**

* Метрика по эксклюзивным словам подтверждает наши убеждения, она выводит такие слова, как: hollywood, fictional, fan, musical 
* Эта тема скорее является шумом (несмотря на ее среднюю размерность), поскольку в ней содержатся слова, выполнящие функциональные задачи в описаниях сюжетов, а не смысловые, поэтому скорее всего мы не увидим различий в этой теме в зависимости от жанров.  


## 14 тема: "Поездки на наземном транспорте"

На 14 тему приходится 2.4% от всех токенов слов.

**Топ по FREX**

![](./14_FREX.PNG)

* Глаголы, обозначающие передвижения, поездки на наземном транспорте: drive, ride, stop, crash, travel
* Сами наземные транспорты (само слово vehicle): train, truck, car, bus
* Другие слова, логически связанные с поездками: station, motel, railway, highway, driver, speed


**Топ по эксклюзивным словам**

* Помимо того, что эта метрика подтверждает наши предыдущие наблюдения - она еще выводит в самый топ такие слова: ranch (+ cowboy), hood, conductor и даже штат США - Техас, в котором судя по всему и происходят действия, связанные с ранчо, поездками по трассе. 

## 15 тема: "Слежка"

**Топ по FREX**

![](./15_FREX.PNG)

* Spy, coat + suit (пальто - при слежке распостраненная одежда в фильмах), agent + pretend, secret
* envelope (конверт), который секретный агент достает судя по всему из своего чемоданчика (briefcase)
* Есть слова, которые сложно логически связать между собой

**Топ по эксклюзивным словам** выводит слишком редкие слова, которые не помогают лучше понять контекст темы

## 16 тема: "Судебный процесс"

**Топ по FREX**

![](./16_FREX.PNG)

* Attorney (прокурор) + accuse (обвинять) - lawyer (адвокат), trial (судебный процесс), sentence (приговор), court (суд), judge (судить), innocence - convict, witness + testify (давать показания) и т.д. - все эти слова логически связаны и представляют собой необходимые атрибуты судебного процесса
* Тема очень хорошая, все слова действительно логичны и ождаемы для такого судебного контекста 

**Топ по эксклюзивным словам**

* Эксклюзивное и достаточно частотное слово для 16-ой темы: governor
* testimony - свидетельские показания
* jury - присяжные
* И др. термины судопроизодства

## 17 тема: "Кража драгоценностей"

**Топ по FREX**

![](./17_FREX.PNG) 

* По первым словам мы понимаем, что 17-ый топик раскрывает тему кражи (steal, thief, robbery, theft и т.д.) драгоценностей (paint, diamond, jewel, crown, jewelry, gold, necklace)
* Откуда крадут: bank, museum, gallery
* Как проникли: FREX выводит нам в топ-список слово sewer (канализация) - возможно это слово раскрывает путь проникновения в публичное здание 
* Тема тоже интересная!

**Топ по эксклюзивным словам** 

* gem (драгоценный камень), pearl (жемчужина)
* Важно подчеркнуть, что эта тема касается ограбления именно в публичном месте - у нас с Вами уже есть отдельная тема про "Преступление в жилом помещении".

## 18 тема: "Школьная/университетская жизнь в кампусе"

**Топ по FREX**

![](./18_FREX.PNG) 

* Учебные заведения: school, college, university
* Учителя & профессора
* Все необходимые атрибуты школьной и/или университетской жизни: friend, project, exercise, lecture, program, bully, rommate
* Места действий: class, hall, facility

**Топ по эксклюзивным словам** 

* campus, classroom
* expel (видимо исключение из учебного заведения)
* в основном, слова совпадают со словами, полученными с помощью FREX

## 19 тема: "Морское путешествие"

**Топ по FREX**

![](./19_FREX.PNG)

* Водные средства передвижения: ship, boat, submarine (подводная лодка), yacht, liner
* Глаголы плыть: sail, swim
* navy - морской флот
* Другие слова, раскрывающие контекст передвижений по воде: aboard, board, cabin, dock (причал), naval (военно-морской), captain
* Водный путь сообщения: ocean
* island

**Топ по эксклюзивным словам**

* ship - эксклюзивное и самое частотное слово для 19-ой темы
* по этой метрике появляются морские жители: shark (акула)
* voyage (морское путешествие), vessel (судно), cruise

## 20 тема: "Полет на самолете & катастрофа"

**Топ по FREX**

![](./20_FREX.PNG)

* А в 20 теме речь о передвижениях на самолете (plane, pilot, flight, passenger, airport, aircraft, airline, airplane)
* Но в этой теме, в отличии от предыдущей, присутсвуют слова, раскрывающие контекст катастрофы (crash, disaster), захвата/угона (hijack) и паники. Так как в топ-списке есть слово fuel, можно предположить, что в каких-то фильмах катастрофа была связана с проблемами с топливом. Кроме того, слово парашут неслучайно попало в эту тему - так пассажиры спасались от авиакрушения
* Неожиданно, что слово snake будет в топе релевантных слов 
* weather: встретить слово погода в таком контексте вполне ожидаемо, так как от погоды очень сильно зависит успешность и возможность полетов на самолете
* Есть также слова, отражающие нелегальную деятельность: smuggle (провозить контрабандой)

**Топ по эксклюзивным словам**

* snake - второе по релевантности!
* hurricane (ураган) - благодаря этой метрике мы узнали какая именная погодная проблема была
* в целом, слова по этой метрике не дают новых инсайтов для 20-ой темы


Прогоняя модель несколько раз, я убедилась, что результат вполне стабильный - большинство тем появляются каждый раз. Однако, нужно отметить, что некоторые темы мигрировали в схожие для себя темы. К сожалению, я не сразу догадалась использовать random seed, поэтому все интепретации относятся к первому прогону - но результат все же стабильный для большинства тем, поэтому интепретации все-таки отражает реальность. 

# Тематическая характеристика для разных жанров

```{r}
topics <- meta_df %>% cbind(doc.topics) 
glimpse(topics)
```

**Статистика**


Для подсчета статистика я буду использовать среднее значение, так как сумма не очень подойдет для неравномерых классов - наш случай. Еще посмотрим на стандартное отклонение на всякий случай.

NB! Темы сейчас будут интепретироваться не в той последовательности, как они представлены в интерактивной визуализации, поскольку я поставила random seed уже после интерактивной визуализации и интепретации тем по ней, но темы получились стабильными и очень похожими - просто последовательность будет другая. 

## 14 тема:"Поездки на наземном транспорте"


```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`1`), SD = sd(`1`)) %>%
  arrange(desc(Mean))
```
В криминимальном жанре доля темы про поездки на наземном транспорте больше, но среднее значение не сильно отличается от жанра mystery. У жанра триллера доля этой темы наименьшая.

## 10 тема: "Банда беглецов"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`2`), SD = sd(`2`)) %>%
  arrange(desc(Mean))
```

Эта тема больше представлена в жанре mystery и crime (разница небольшая) - меньше всего в триллерах. 


## 2 тема: "Преступление в жилом помещении"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`3`), SD = sd(`3`)) %>%
  arrange(desc(Mean))
```

Больше всего характерна для триллера! Потом для crime и mystery.

## 11 тема: “Минирование предприятия и взятие заложников”

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`4`), SD = sd(`4`)) %>%
  arrange(desc(Mean))
```

Этот результат был ожидаемый :) 

Действительно, в жанрах криминала чаще происходят как раз такие вещи.

## 3 тема: “Последствия супружеской измены”


```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`6`), SD = sd(`6`)) %>%
  arrange(desc(Mean))
```

Для жанра мистики - это наиболее характерная тема, но разница с триллером небольшая. Эта тема меньше всего представлена для crime - это тоже логично, поскольку жанр криминала предпологает какие-то серийные убийства, банды и т.д. Редко в жанрах криминала будет рассказываться о мести между супругами и т.д. 

## 12 тема: "Лечение в больнице & потеря памяти"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`8`), SD = sd(`8`)) %>%
  arrange(desc(Mean))
```

Тема больницы наиболее характерна для триллеров и наименее характерна для мистического жанра - тоже логично.

## 20 тема: "Полет на самолете & катастрофа"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`9`), SD = sd(`9`)) %>%
  arrange(desc(Mean))
```

Для жанра crime эта тема чуть больше характерна, чем для жанра mystery, а наименне характерна (достаточно значительно) для жанра триллера. 

## 5 тема: "Бандиты & незаконная деятельность"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`10`), SD = sd(`10`)) %>%
  arrange(desc(Mean))
```

Ожидаемо, что тема бандитов и их незаконной деятельности будет наиболее характерна именно для жанра crime. Но я ожидала, что наименее характерна эта тема будет для жанра mystery.

## 9 тема: "Противостояние государств"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`11`), SD = sd(`11`)) %>%
  arrange(desc(Mean))
```

Логично было бы предположить, что тема секретных агентов, терроризма, войны, противостояний государств скорее характерна для триллеров, чем для crime и mystery.

## 4 тема: "Расследование убийства и экспертиза доказательств"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`12`), SD = sd(`12`)) %>%
  arrange(desc(Mean))
```

Тема достаточно частотная (на нее приходится почти 7% токенов), поэтому доли у всех достаточно серьезные, но все-таки детективный контекст больше характерен для триллеров, чем для других жанров. Я это учту, когда в следующий раз буду выбирать себе фильм посмотреть :)

## 18 тема: "Школьная/университетская жизнь в кампусе"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`16`), SD = sd(`16`)) %>%
  arrange(desc(Mean))
```

Ой, а вот этот результат неожиданный! Я думала, что у триллеров будет бОльшая доля школьной тематики среди остальных жанров. 

## 19 тема: “Морское путешествие”

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`17`), SD = sd(`17`)) %>%
  arrange(desc(Mean))
```

Морская тематика характерна больше для триллеров и наименее характерна для crime!

## 17 тема: "Кража драгоценностей"

```{r}
topics %>% group_by(Genre) %>%
  summarise(Mean = mean(`19`), SD = sd(`19`)) %>%
  arrange(desc(Mean))
```

Опять неожиданность... Я была уверена, что тематика ограблений все-таки наиболее присуща криминальному жанру.

Я проинтепретировала различия только темам, которые оказались очень стабильны для множества прогонов модели, когда не был проставлен random seed. Некоторые темы мигрировали в другие - схожие, а какие-то наоборот делились на несколько.

# Заключение

Выбирать фильмы мне нужно в жанре триллера, так как в нем чаще других жанров представлена тема расследование убийств и экспертиза доказательств и наименее представлена та самая бандитская тематика (5, 10 темы). Но я понимаю, что модель должна была получиться более стабильной, я попробую использовать метрики качества для моделей с разным количеством тем, чтобы прийти к наилучшему результату (просто для себя). 




